<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>semantic segmentation | Xin LAI</title>
    <link>https://x-lai.github.io/tags/semantic-segmentation/</link>
      <atom:link href="https://x-lai.github.io/tags/semantic-segmentation/index.xml" rel="self" type="application/rss+xml" />
    <description>semantic segmentation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 17 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://x-lai.github.io/img/icon-192.png</url>
      <title>semantic segmentation</title>
      <link>https://x-lai.github.io/tags/semantic-segmentation/</link>
    </image>
    
    <item>
      <title>U-Net</title>
      <link>https://x-lai.github.io/post/u-net/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://x-lai.github.io/post/u-net/</guid>
      <description>

&lt;h1 id=&#34;u-net-convolutional-networks-for-biomedical-image-segmentation&#34;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/h1&gt;

&lt;p&gt;现在训练一个深度网络需要很多已标注的训练样本。本文提出一种网络结构以及训练技巧，并大大依靠data augmentation，使用有限的标注样本高效训练。该网络结构包括一个用来捕捉context的contracting path，以及一个对称的用来准确定位的expanding path。实验表明用很少的数据就能end-to-end训练出一个效果很好的网络。&lt;/p&gt;

&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;本文以FCN为基础，对contracting path进行补充，添加了一个expanding path，并且为了精确定位，和来自contracting path的高分辨feature map结合起来形成upsampled output。（为什么要先contract在expand？借助了auto-encoder的思想，中间将特征维度降低，是为了将有用的特征聚集起来，并且排除一些噪声或者low-level的信息。）&lt;/p&gt;

&lt;h2 id=&#34;overlap-tile-strategy&#34;&gt;Overlap-tile Strategy&lt;/h2&gt;

&lt;p&gt;U-Net使用的卷积操作的pad=0，所以每次卷积完之后，会使得feature map的size减少2。所以最终经过contracting path和expanding path之后输出的feature map会比输入图像的size少很多。所以需要将输入的最原始的图像的size扩大，使得最终输出的feature map和最原始的图像size相同。那么如何扩大输入的图像呢？本文提出通过将最原始图像的边缘做一个镜像操作来扩大它的size。&lt;/p&gt;

&lt;h2 id=&#34;data-augmentation&#34;&gt;Data augmentation&lt;/h2&gt;

&lt;p&gt;除了overlap-tile strategy，本文还提出对有限的图像使用elastic deformation，进而达到data augmentation的目的。通过$3\times 3$的grid使用random displacement得到smooth deformation。因为本文的背景是细胞的分割，所以使用elastic deformation是合理的，而且还能使得网络学到一种对这种deformation的invariance。此外，shift和rotation以及gray value invariance都可以通过类似的augmentation方法学到。&lt;/p&gt;

&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;

&lt;p&gt;实质上，分割任务就是对每个像素都进行分类，所以最终的输出为$K$个feature maps。同时，为了处理touching objects（同类objects叠在一起）的边界处，最终损失函数还需要对这种边界处的像素提高权重。所以最终损失函数（也叫energy function）为：$E=\sum_{x\in \Omega}{w(x)log(p_{l(x)}(x))}$ 。其中$l(x)$表示像素x的真实label。$p_k(x)$表示像素x在第$k$类的概率值。&lt;/p&gt;

&lt;p&gt;其中weight map $w(x)$通过以下公式计算:$$w(x)=w_c(x)+w_0\cdot exp(-\frac{(d_1(x)+d_2(x))^2}{2\sigma^2})$$&lt;/p&gt;

&lt;p&gt;其中$w_c$用于平衡class frequencies。$d_1(x)$表示像素x到最近细胞的边界的距离，$d_2(x)$表示像素x到第二近的细胞的边界的距离。在实验中，设置$w_0=10,\sigma=5$。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
